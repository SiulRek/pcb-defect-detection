{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing Framework for PCB Defect Detection<br>\n",
    "![System Test Engineering Logo](related/logo_fhj_stm.jpg)<br>\n",
    "---\n",
    "\n",
    "**Master's Degree Project in System Test Engineering**  \n",
    "**FH JOANNEUM - University of Applied Sciences**\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Luis Kraker  \n",
    "**Supervisor:** DDr. Gudrun Schappacher-Tilp  \n",
    "**Date:** 10<sup>th</sup> December, 2023    \n",
    "\n",
    "---\n",
    "\n",
    "## Foreword\n",
    "This document is part of my ongoing PCB (Printed Circuit Board) defect detection project for my master's degree in System Test Engineering at FH JOANNEUM. The project will be part of the ENDLESS initiative (Enabling Dependable Embedded Systems), which is supported by the Austrian Research Promotion Agency through the COIN program. This document focuses on the image preprocessing framework that I created for this project. It aims to provide detailed information about the framework's code structure and features.\n",
    "\n",
    "I am receiving ongoing and valuable guidance from Ms. Schappacher, a senior lecturer at FH JOANNEUM, in developing the software solutions that are a crucial part of this framework. The document, presented as an interactive Jupyter notebook, includes not just text but also links to software modules and live demonstrations.\n",
    "\n",
    "It is important to note that this document focuses solely on the image preprocessing framework of the project and does not cover any aspects of the PCB defect detection model, which is still in development. Finally, because I am eager to grow in my technical expertise, I am open to any feedback that can contribute to my overall development in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "1. [Introduction to the PCB Defect Detection Project](#1-introduction-to-the-pcb-defect-detection-project)\n",
    "1. [The Role of Image Preprocessing](#2-the-role-of-image-preprocessing)\n",
    "1. [Preprocessing Experiences](#3-preprocessing-experiences)\n",
    "1. [Inspiration and Framework Conceptualization](#4-inspiration-and-framework-conceptualization)\n",
    "1. [Interactive Exploration of the Image Preprocessor](#5-interactive-exploration-of-the-image-preprocessor)\n",
    "1. [Code Framework Overview](#6-code-framework-overview)\n",
    "1. [Understanding the ImagePreprocessor Class](#7-understanding-the-imagepreprocessor-class)\n",
    "1. [Understanding the StepBase Class](#8-understanding-the-stepbase-class)\n",
    "1. [Constructing Custom Preprocessing Step](#9-constructing-custom-preprocessing-step)\n",
    "1. [Serialization of the Pipeline with JSON](#10-serialization-of-the-pipeline-with-json)\n",
    "1. [Understanding the ClassInstancesSerializer](#11-understanding-the-classinstancesserializer)\n",
    "1. [Conclusion and Further Steps](#12-conclusion-and-further-steps)\n",
    "1. [Author's Q&A](#authors-qa)\n",
    "1. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Chapter1'></a>\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction to the PCB Defect Detection Project\n",
    "Printed Circuit Boards (PCBs) are critical components of electronic devices, but detecting defects during production is difficult. These flaws can have an impact on device performance and safety, making detection a critical step.[[1]](#references) Through Machine Learning (ML), the hope is to improve this detection process.\n",
    "\n",
    "While traditional methods of inspecting PCBs, such as Automatic Optical Inspection (AOI) systems, are used, they frequently struggle with the complexity of modern PCB designs, resulting in false positives—incorrectly marking good areas as defective.[[1]](#references) This challenge underscores the importance of the ML approach, which requires the availability of high-quality image data suitable for effective machine learning.\n",
    "\n",
    "**Stages of the PCB Defect Detection Workflow** \n",
    "\n",
    "The creation of a system for detecting defects in PCBs follows a structured workflow that includes several key stages:\n",
    "\n",
    "- Identifying Defect Types: Specifying the types of defects to look for.\n",
    "\n",
    "- Image Preprocessing: Collecting and preparing images in preparation for model.\n",
    "\n",
    "- Model Development: creating an ML model for exact defect detection in PCBs.\n",
    "\n",
    "- Model optimization: is about training the model with high-quality data in order to validate accuracy and reduce false positives.\n",
    "\n",
    "The stages of the preceding list represent the critical phases in the development of the PCB defect detection tool. Given the model's dynamic nature, which may necessitate optimization, retraining with new data, adjustments for detecting different defect types, or producing different outputs, these stages are expected to be cyclical. This iterative approach highlights the significance of continuous improvement response to readapted detection requirements. This is why a solid test strategy is also required to make these cycles easier while ensuring the tool's effectiveness and functionality when changes are made.\n",
    "\n",
    "**Focus of this Documention**\n",
    "\n",
    "The focus of this documentation is the image preprocessing framework, an important component in preparing images for analysis by the PCB defect detector model.  Image preprocessing involves transforming raw image data into a format that is not only standardized but also optimized for compatibility with ML models. It entails filtering the images, maintaining consistency, and bringing them up to a quality from which the machine learning model may effectively learn.[[2]](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter2'></a>\n",
    "## 2. The Role of Image Preprocessing\n",
    "When working with images in the ML process, image preprocessing is a critical stage. It's not only about getting the images ready; it's also about making sure they're in good enough condition for the models to learn from. Here are the main reasons on why it is critical:\n",
    "\n",
    "- Formatting and Standardization: Images must be correctly formatted before being fed into a ML model. This includes ensuring that their colors are altered as needed, positioned correctly, and that they are all the same size. Convolutional Neural Networks (CNNs) require this since their layers expect uniformly sized inputs.[[2]](#references)\n",
    "\n",
    "- Quality Improvement: Good preprocessing aids in extracting the relevant features of an image from which the model must learn. Preprocessing seeks to improve image data by improving specific visual attributes that are crucial for subsequent processing and analysis activities or suppressing undesired distortions.[[3]](#references) The goal is to enhance the quality of the data so that the model can deal with it more effectively. Just as numbers are normalized and standardized in other ML Solutions, image preprocessing ensures that the model sees the images in a way that allows it to learn effectively.[[4]](#references)\n",
    "\n",
    "- Increased Speed: When images are properly preprocessed, everything else in the machine learning process may move more quickly. Training models can take less time, and predictions can be made more quickly. This is especially significant when a large number of images exists to sort through because it allows us to accomplish more in less time.[[2]](#references)\n",
    "\n",
    "In summary, preprocessing is suggested, not only for PCB defect detection, but also for any other image-based ML project. It improves the model's performance, provides faster results, and guarantees that the learning process runs smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter3'></a>\n",
    "## 3. Preprocessing Experiences\n",
    "At the beginning of my journey to develope a tool for PCB defect detection using ML, I created a dedicated Jupyter Notebook called [image_preprocessing_evaluation.ipynb](./image_preprocessing_evaluation.ipynb). This notebook was used to evaluate multiple image preprocessing procedures, each aiming to enhance the quality of PCB images for improved defect detection.\n",
    "\n",
    "**Key Preprocessing Steps Investigated**\n",
    "\n",
    "1. Histogram Equalization: Balances image contrast.\n",
    "1. Noise Reduction: Clears up image clarity.\n",
    "1. Grayscale Conversion: Simplifies image complexity.\n",
    "1. Resizing: Standardizes image dimensions.\n",
    "1. Perspective Correction: Aligns image orientation (work in progress).\n",
    "1. Thresholding: Enhances specific image features.\n",
    "1. Morphological Operations: Attempts to refine image texture (results were mixed).\n",
    "1. Normalization: Adjusts pixel value scales.\n",
    "1. Standardization: Aims for uniform pixel values (found redundant after Thresholding or Normalization).\n",
    "\n",
    "**Evaluation Method**\n",
    "\n",
    "For evaluating these preprocessing steps, the Kaggle PCB Defect Dataset [[5]](#references) was utilized.\n",
    "The TensorFlow framework was used to handle the image collection efficiently.\n",
    "I included in the TensorFlow framework built-in image preprocessing routines from OpenCV (cv2), allowing for easy application of preprocessing stages.\n",
    "\n",
    "**Realizations and insights**\n",
    "\n",
    "While working on the notebook, I became aware of the vast number of potential image preprocessing steps and parameters. The global histogram equalization stage was a prime example (see code snippet above). The preprocessing step included mapping each image to the `global_histogram_equalization` function. Following this mapping, the images, which were originally in TensorFlow format, were transformed to OpenCV format. In this format, the equalization procedure was then implemented. Finally, the images were transformed back to TensorFlow format for additional processing or analysis. This method used in the notebook highlighted the difficulties and limitations of developing basic function-based solutions:\n",
    "- Sequence Flexibility: Each experiment with different preprocessing steps required altering the dataset mapping sequence. This method included carefully aligning each step to ensure that the output of one preprocessing step was correctly fed into the next. The procedure was prone to errors, as accidental misalignments or incorrect dataset mappings could easily occur, resulting in wrong results and further debugging efforts.\n",
    "- Parameter Adjustability: Changing preprocessing parameters was limited to changes within the functions themselves. This lack of flexibility hindered automatic variations or dynamic adaptations, limiting the ability to efficiently explore and optimize different preprocessing parameter settings.\n",
    "- Reproducibility: Without the ability to serialize (save and load) the specific sequence of preprocessing steps, it becomes difficult to replicate the exact same preprocessing sequence for other datasets or experimental circumstances. This makes consistent evaluation and comparison of results difficult.\n",
    "- Modularity and Integration: The inability to serialize preprocessing sequences restricts the potential for integrating the developed processes sequence into larger, more complex systems. Ideally, a successful preprocessing sequence should be saved to a file, which can then be easily loaded and applied in other modules or projects.\n",
    "\n",
    "It became clear that a more integrated and adaptable preprocessing solution was required. In response to this realization, the following chapter discusses the development of a robust framework aimed at addressing these complexities, subsequently progressing the development of the PCB defect detection tool.\n",
    "\n",
    "\n",
    "```python\n",
    "def global_histogram_equalization(image_tensor, target_tensor):\n",
    "    # Transformation to an Image Format accepted by OpenCV\n",
    "    cv_img = image_tensor.numpy().astype('uint8')\n",
    "\n",
    "    # Apply histogram equalization to each of the RGB channels independently\n",
    "    channels = cv2.split(cv_img)\n",
    "    eq_channels = [cv2.equalizeHist(ch) for ch in channels]  \n",
    "    cv2_eq_image = cv2.merge(eq_channels)\n",
    "    \n",
    "    # Conversion back to tensor\n",
    "    tf_eq_image = tf.convert_to_tensor(cv2_eq_image, dtype=tf.uint8) \n",
    "    \n",
    "    return (tf_eq_image, target_tensor)\n",
    "\n",
    "# Map the dataset elements to global_histogram_equalization\n",
    "image_dataset_equalized_glo = image_dataset.map(\n",
    "    lambda img, tgt: tf.py_function(\n",
    "        func=global_histogram_equalization, \n",
    "        inp=[img, tgt], \n",
    "        Tout=(tf.uint8, tf.int8)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter3.5'></a>\n",
    "## 4. Inspiration and Framework Conceptualization\n",
    "The knowledge gained from testing various image preprocessing techniques, together with the insights gained from practicing basic machine learning in Python with scikit-learn, a famous Python machine learning tool, has lead me to a significant realization. Especially the pipeline technique employed in scikit-learn inspired me. A `Pipeline` object in scikit-learn applies a sequence of transformations and a final estimator successively.[[6]](#references) The result of the preceding phase is fed into each stage of the `Pipeline`, speeding the data processing and modeling process. This method is extremely useful for assuring a consistent and efficient process, especially when doing many data transformation phases.\n",
    "\n",
    "This inspiration sparked the idea for a comparable approach for image preprocessing in PCB defect detection. Unlike the scikit-learn `Pipeline`, which involves learning from data and includes a fitting process, the image preprocessing framework focuses solely on transforming or processing the data without any learning or fitting stage.\n",
    "\n",
    "The envisioned framework seeks to provide an organized and fast approach to apply multiple preprocessing steps to images. This framework not only allows for simple experimentation with different combinations of steps, but also aligns with the need for systematic and reproducible preprocessing in ML for image analysis. This chapter represents the start of the projects target to develop an efficient image preprocessing tool for PCB defect detection.\n",
    "\n",
    "The next sections of the documentation lead through the image preprocessing framework step by step, enabling interactive reading (running of Jupyter Notebook Python cells). Throughout these sections, links to software modules can be found, providing further insights and answers on implementation questions that may arise while reading. Additionally, a chapter titled [Author's Q&A](#authors-qa) is included, which aims to address various questions about the rationale behind certain implementation decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter5'></a>\n",
    "## 5. Interactive Exploration of the Image Preprocessor\n",
    "The interactive tour of creating an image preprocessing pipeline begins here. This hands-on activity will facilitate experimentation with different preprocessing stages applied to PCB images, enabling a visual assessment of the image quality. At the same time it presents the developed image preprocessing framework.\n",
    "\n",
    "**Context-Specific Key Definitions**\n",
    " \n",
    "- Preprocessing Step: This term refers to a specific stage in image preprocessing that is encapsulated within a specific class. `GaussianBlurrer` and `GlobalHistogramEqualizer` are two examples of processing actions in the image preprocessing workflow.\n",
    "- Pipeline: This word refers to a costumized ordered sequence of preprocessing steps. The `ImagePreprocessor` is able to apply these pipeline to an image dataset.\n",
    "- Parameters: This word refers, unless otherwise specified, to the arguments of the corresponding preprocessing step class, which are essential for configuring each preprocessing step in the pipeline.\n",
    "- Pipeline Configuration: This term refers to the chosen combination of preprocessing steps and their associated parameters in a pipeline. It essentially describes the order and settings for each preprocessing step used.\n",
    "\n",
    "**Creation of the Pipeline**\n",
    "1. Select preprocessing steps: Start by selecting from various options like histogram equalization, noise reduction, grayscale conversion, among others.\n",
    "1. Order preprocessing steps: Order the steps carefully, as their order might have a considerable impact on the ultimate result. \n",
    "1. Set the preprocessing steps parameters: Assign values to the arguments of the preprocessing steps.\n",
    "1. Observation and experimentation: Experiment with different preprocessing step combinations and sequences. \n",
    "\n",
    "Tipp: Use editor guidance features to find different steps or parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import source.load_raw_data.kaggle_dataset as kaggle_dataset\n",
    "from source.utils.pcb_visualization import PCBVisualizerforTF\n",
    "from source.image_preprocessing.image_preprocessor import ImagePreprocessor\n",
    "import source.image_preprocessing.preprocessing_steps as steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "image_dataset = kaggle_dataset.load_tf_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ImagePreprocessor()\n",
    "\n",
    "#TODO Build the pipeline here:\n",
    "pipeline = [\n",
    "    steps.GaussianBlurFilter(kernel_size=(5,5), sigma=0.3),\n",
    "    steps.AdaptiveHistogramEqualizer(clip_limit=2.0, tile_gridsize=(8,8)),\n",
    "    steps.RGBToGrayscale(),\n",
    "    steps.AdaptiveThresholder(block_size=15, c=-2),\n",
    "    steps.SquareShapePadder(),\n",
    "    steps.ShapeResizer(desired_shape=(1000,1000))\n",
    "    # ... Add/change steps\n",
    "]\n",
    "\n",
    "\n",
    "preprocessor.set_pipe(pipeline)\n",
    "processed_dataset = preprocessor.process(image_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Visual Comparison: Conduct a side-by-side comparison of the original and processed images to visualize the results of the built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcb_visualizer = PCBVisualizerforTF()\n",
    "pcb_visualizer.plot_image_comparison(image_dataset, processed_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following an examination of the image preprocessing framework's capabilities and the methodology of building a pipeline for image dataset processing, the following chapters will delve into the framework's underlying code. This chapters will explore the code's key elements in order to present its contributions to the overall framework's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter-6'></a>\n",
    "## 6. Code Framework Overview\n",
    "Moving from interactive exploration of the image preprocessing framework, the focus now shifts to understanding the architecture behind it. \n",
    "\n",
    "**Framework Components**\n",
    "\n",
    "The image preprocessing framework includes the following key-components:\n",
    "\n",
    "- `ImagePreprocessor`: The main driver of the pipeline, managing the flow and application of preprocessing steps.\n",
    "- `ClassInstancesSerializer`: A serialization utility that allows the saving and loading of pipelines.\n",
    "- `StepBase`:  An abstract base class that defines the blueprint for all preprocessing steps.\n",
    "- Preprocessing Steps: In the specific context of the code framework they represent child classes of `StepBase` that each encapsulate a specific preprocessing function, such as `AdaptiveHistogramEqualizer`.\n",
    "\n",
    "**Understanding the Structure with UML**\n",
    "\n",
    "The attached UML (Unified Modeling Language) diagram visually breaks down these components and their relationships. This high-level overview serves as a map to navigate the interactions within the framework. To simplify the visual representation of the Image Preprocessing Framework only public methods and attributes are shown in the diagram.\n",
    "\n",
    "![UML Diagram](./related/image_preprocessing_uml.png)\n",
    "\n",
    "In the diagram, it is visible how `ImagePreprocessor` orchestrates the sequence of steps, while `ClassInstancesSerializer` handles the serialization of instances/pipeline. `StepBase` outlines the structure that each preprocessing step must adhere to, ensuring consistency and reliability.\n",
    "\n",
    "**Preparing for Deeper Dives**\n",
    "\n",
    "The next sections will go over each component depicted in the UML diagram. This includes a look at how the `ImagePreprocessor` controls the preprocessing pipeline, a look at `StepBase` and structure of it's subclasses, and a look at the serialization possibilities provided by `ClassInstancesSerializer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter7'></a>\n",
    "## 7. Understanding the ImagePreprocessor Class\n",
    "The `ImagePreprocessor` class is the primary component of the Image Preprocessing Framework, managing the pipeline, consisting of preprocessing steps for PCB images. The class is defined in the [image_preprocessing.py](../image_preprocessor.py) module.\n",
    "\n",
    "The `ImagePreprocessor` class has the following public attributes and methods at its core:\n",
    "\n",
    "**Attributes**:\n",
    "\n",
    "- `pipeline`: A sequence of steps, derived from `StepBase`, that are executed on an image dataset.\n",
    "- `serializer`: A `ClassInstancesSerializer` instance responsible for saving and loading the pipeline configuration.\n",
    "\n",
    "**Methods**:\n",
    "\n",
    "- `set_pipe`: Establishes the preprocessing steps in the pipeline.\n",
    "- `pipe_append`: Allows for adding a step to the pipeline.\n",
    "- `pipe_pop`: Removes and returns the last step from the pipeline\n",
    "- `process`: Applies the pipeline to an image dataset in sequence.\n",
    "- `save_pipe_to_json` and `load_pipe_from_json`: Methods for serialization and deserialization, crucial for maintaining the pipeline’s configuration.\n",
    "- `load_randomized_pipe_from_json`: Similar to `load_pipe_from_json`, but allows also for randomization of the preprocessing steps arguments.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "The `ImagePreprocessor` class methodically manages a series of image preprocessing steps, specifically designed for PCB images. It facilitates the flexible assembly and alteration of the processing sequence, providing structured and repeatable image transformations. It has serialization features ensuring for efficient saving and loading of pipeline configurations.\n",
    "\n",
    "To test the functionality and reliability of the `ImagePreprocessor` a test suite was developed. This test suite can also be used to gain deeper insights into the dynamic behaviour of the class. The test suite is defined in the [image_preprocessing_test.py](../tests/image_preprocessing_test.py) module.\n",
    "\n",
    "The `ImagePreprocessor` enforces the use of `StepBase` subclasses, ensuring a standardized approach to process images within a pipeline. Building on this, the focus of the next chapter shifts to the `StepBase` class, which serves as the foundation for each preprocessing step. This chapter will provide details about the class and explain how it defines the structure and functionality of each step in the pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter8'></a>\n",
    "## 8. Understanding the StepBase Class\n",
    "The `StepBase` class is the next fundamental component of the Image Preprocessing Framework, acting as a blueprint for each preprocessing step applied to PCB images. Because of this it operates as an abstract base class. The `StepBase` class is defined in the [step_base.py](../preprocessing_steps/step_base.py) module.\n",
    "\n",
    "The `StepBase` class has the following public attributes and methods at its core:\n",
    "\n",
    "**Attributes:**\n",
    "- `default_output_datatypes`:(Class Attribute) Dictates the default data types for the output of the preprocessing steps, with image data typically as tf.uint8 and target data as tf.int8. This attribute is fixed and should not be modified by subclasses.\n",
    "- `arguments_datatype`: (Class Attribute) Specifies the expected data types for the arguments of each preprocessing step.\n",
    "- `name`: (Class Attribute) Acts as a unique identifier for each preprocessing step.\n",
    "- `output_datatypes`: Dictates the data types for the output of the specific preprocessing step. Defaults to `default_output_datatypes`.\n",
    "- `parameters`: Holds the parameters necessary for the specific preprocessing functionality, they are derived from the initialization of the instance.\n",
    "\n",
    "**Methods:**\n",
    "- `process_step`: (Abstract Method) To be implemented in child classes, defining the specific preprocessing operations.\n",
    "- `_tensor_pyfunc_wrapper` and `_nparray_pyfunc_wrapper` (private methods): Static methods acting as decorators for mapping the Tensor or NumPy array representation of the image into the preprocessing step method. They ensure a correct mapping of TensorFlow datasets to the related `process_step` method.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "The `StepBase` class enforces a structured approach, requiring child classes to implement the `process_step` method and specify `arguments_datatype` and `name`.\n",
    "It provides decorators for flexibility in implementing preprocessing steps as Python functions working with either NumPy arrays or Tensors.\n",
    "The class facilitates the integration of preprocessing steps within the image processing pipeline, emphasizing modularity and customization.\n",
    "\n",
    "A comprehensive test suite, essential for ensuring the robustness and functionality of the `StepBase` class, can be found in [step_base_test.py](../tests/step_base_test.py).\n",
    "\n",
    "The next chapter shifts the focus to practical implementation of preprocessing steps. It presents an interactive guidance for the development and integration of a custom image preprocessing step into the pipeline. The costum preprocessing step class is going to inherit from the recently introduced `StepBase` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter9'></a>\n",
    "## 9. Constructing Custom Preprocessing Step\n",
    "This chapter provides guidance on constructing a custom preprocessing step, with a specific focus on demonstating the process of integrating a new step into an existing image preprocessing pipeline. The objective is to integrate a `PixelOffseter` preprocessing step into the image preprocessing framework and include it to the already existing pipeline from [Chapter 5](#5-interactive-exploration-of-the-image-preprocessor). The following steps outline the procedure:\n",
    "\n",
    "1. Create a python file called pixel_offsetting.py in the [single_steps](../preprocessing_steps/single_steps/) folder.\n",
    "2. Insert the provided code into this file. The code defines a class `PixelOffseter` derived from `StepBase`, which applies an offset to each pixel in an image tensor:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from source.image_preprocessing.preprocessing_steps.step_base import StepBase\n",
    "\n",
    "class PixelOffseter(StepBase):\n",
    "    \"\"\"A preprocessing step that applies an offset to each pixel in an image tensor.\n",
    "       The default offset value is 10.\"\"\"\n",
    "\n",
    "    arguments_datatype = {'offset': int}\n",
    "    name = 'Pixel Offseter'\n",
    "\n",
    "    def __init__(self, offset=10):\n",
    "        \"\"\"Initializes the PixelOffseter object for integration into an image preprocessing pipeline.\n",
    "\n",
    "           Args:\n",
    "               offset (int): The value used to offset each pixel in the image tensor. Default is 10.\n",
    "        \"\"\"\n",
    "        super().__init__(locals())\n",
    "    \n",
    "    @StepBase._tensor_pyfunc_wrapper\n",
    "    def process_step(self, image_tensor):\n",
    "        image_tensor = tf.cast(image_tensor, self.output_datatypes['image'])\n",
    "        offset_value = tf.constant(self.parameters['offset'], self.output_datatypes['image'])\n",
    "        offset_image = image_tensor + offset_value\n",
    "        return offset_image\n",
    "\n",
    "```\n",
    "\n",
    "3. Integrate the `PixelOffseter` class into the existing set of preprocessing steps. This is achieved by including an import statement in the [__init__.py](../preprocessing_steps/__init__.py) file:\n",
    "\n",
    "```python\n",
    "from source.image_preprocessing.preprocessing_steps.single_steps.pixel_offsetting import PixelOffseter\n",
    "```\n",
    "\n",
    "4. Add a key-value pair for the new preprocessing step in the mapping dictionary within [step_class_mapping.py](../preprocessing_steps/step_class_mapping.py):\n",
    "```python\n",
    "    'Pixel Offseter': steps.PixelOffseter\n",
    "```\n",
    "\n",
    "5. Add the *Pixel Offseter* object to the JSON file [template.json](../pipelines/template.json) with the specified *offset* parameter:\n",
    "\n",
    "    <i>\"Pixel Offseter\": {\"offset\": 10}</i>\n",
    "\n",
    "6. Modify [single_step_test.py](../tests/single_step_test.py) to test the `PixelOffseter` step with designated step parameters:\n",
    "```python\n",
    "#TODO Select Step to test here!\n",
    "from source.image_preprocessing.preprocessing_steps import PixelOffseter as StepToTest\n",
    "STEP_PARAMETERS = {'offset': 30}\n",
    "```\n",
    "7. Run the test script to confirm that all tests pass.\n",
    "8. After successful testing, incorporate the newly developed step into the preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(steps)\n",
    "# preprocessor.pipe_append(steps.PixelOffseter(offset=30))  #TODO Uncomment this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the modified pipeline\n",
    "processed_dataset = preprocessor.process(image_dataset)\n",
    "pcb_visualizer.plot_image_comparison(image_dataset, processed_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Having established the methodology for constructing a custom preprocessing step such as the `PixelOffseter`, the following chapter focuses on the  pipeline's serialization capability of the `ImagePreprocessor`. This chapter will look at how the pipeline can be serialized to make saving and reloading configurations easier for efficient reuse and sharing. Moreover, this chapter will introduce the functionality of loading a pipeline with randomized parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter10'></a>\n",
    "## 10. Serialization of the Pipeline with JSON\n",
    "This chapter focuses on the `ImagePreprocessor` class and its capability to serialize the pipeline configuration using JSON. This feature is crucial for saving and retrieving pipeline configurations as required.\n",
    "\n",
    "**Save and reload Pipeline**\n",
    "\n",
    "In the previous chapter, a pipeline was successfully constructed. The subsequent step involves storing this pipeline to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(os.path.curdir,  'related', 'pipeline.json')\n",
    "preprocessor.save_pipe_to_json(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline was stored to [pipeline.json](./related/pipeline.json). Before reloading the pipeline modifications to the pipeline, including alterations in parameter values, the sequence of steps, or the application of different steps, are welcome. It is important to note that the order of the preprocessing step entries in the JSON file corresponds to their sequence in the pipeline. For additional preprocessing steps and argument options, refer to the file [template.json](../pipelines/template.json). After finalizing these modifications, the `ImagePreprocessor` is capable of loading the updated pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.load_pipe_from_json(json_path)\n",
    "print(preprocessor.get_pipe_code_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of the modified pipeline\n",
    "processed_dataset = preprocessor.process(image_dataset)\n",
    "pcb_visualizer.plot_image_comparison(image_dataset, processed_dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline Randomization**\n",
    "\n",
    "A significant challenge in the context of preprocessing PCB images is identifying appropriate parameters for each preprocessing step. Manually adjusting parameters within preprocessing steps is time consuming and inefficient. To improve this process, an additional feature that makes hyperparameter tuning easier was implemented. The feature developed allows the specification of parameter ranges or distributions.\n",
    "\n",
    "\n",
    "This feature involves using the JSON file to specify ranges or distribution of the parameters. The entry below can be copied into [pipeline.json](./related/pipeline.json). \n",
    "\n",
    "    {\n",
    "        \"Gaussian Blur Filter\": {\n",
    "            \"kernel_size\": [[3,3],[5,5],[7,7]],\n",
    "            \"sigma\": {\"distribution\": \"poisson\", \"lam\": 3}\n",
    "        },\n",
    "        \"Adaptive Histogram Equalizer\": {\n",
    "            \"clip_limit\": {\"distribution\": \"uniform\", \"low\": 0, \"high\": 3},\n",
    "            \"tile_gridsize\": [[3,3],[5,5],[8,8]]\n",
    "        },\n",
    "        \"RGB To Grayscale\": {},\n",
    "        \"Adaptive Thresholding\": {\n",
    "            \"block_size\": \"[15]*10 + [13]*8 + [17]*6\",\n",
    "            \"c\": {\"distribution\": \"gaussian\", \"loc\": -2, \"scale\": 1}\n",
    "        },\n",
    "        \"Shape Resizer\": {\n",
    "            \"desired_shape\": \"[[1000,1000]]*5 + [[1500,1500]]*4\",\n",
    "            \"resize_method\": [\"bilinear\", \"bilinear\", \"nearest\", \"bicubic\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "The JSON entry of above for the randomized image preprocessing pipeline allows the definintion of parameter ranges and distributions for each preprocessing step:\n",
    "\n",
    "- Parameter Range with List: Parameters can be specified as a list of values. For example, *\"kernel_size\": [[3,3],[5,5],[7,7]]* in *\"Gaussian Blur Filter\"* allows the `ImagePreprocessor` to randomly choose one of these kernel sizes. \n",
    "- Parameter Range with String: Certain parameters can be defined using a string that represents a weighted list of values. For instance, <i>\"block_size\": \"[15]*10 + [13]*8 + [17]*6</i>\" in *\"Adaptive Thresholding\"* creates a weighted list of block sizes for the system to select from. The [parse_and_repeat_test.py](../../utils/tests/parse_and_repeat_test.py) file provides additional insights.\n",
    "- Parameter Distribution: Parameters can also be defined using a statistical distribution. For example, *\"sigma\": {\"distribution\": \"poisson\", \"lam\": 3}* sets *sigma* in *\"Gaussian Blur Filter\"* to follow a Poisson distribution with lambda = 3. Note, when specifying distributions only parameters of type float or int are allowed. The [get_sample_from_distribution_test.py](../../utils/tests/get_sample_from_distribution_test.py) file provides additional insights.\n",
    "\n",
    "Modifications to the entries in the JSON file are permissible and encouraged. After making the desired changes, the updated pipeline configuration can be displayed and utilized for image preprocessing. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell several times to observe how the step parameters vary.\n",
    "preprocessor.load_randomized_pipe_from_json(json_path)\n",
    "print(preprocessor.get_pipe_code_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon exploring the concepts of pipeline serialization and randomization, the next chapter will introduce the underlying class that manages these processes in support of the `ImagePreprocessor`. This chapter aims to provide an overview of the `ClassInstancesSerializer` class's structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter11'></a>\n",
    "## 11. Understanding the ClassInstancesSerializer \n",
    "The `ClassInstancesSerializer` is another fundamental component of the Image Preprocessing Framework that handles the serialization and deserialization of class instances or in this case the pipeline. It converts class instances and arguments to JSON and vice versa, making it especially useful for hyperparameter tuning and model experimentation. This class is defined in the [class_instances_serializer.py](../../utils/class_instances_serializer.py) module.\n",
    "\n",
    "The `ClassInstancesserializer` class has the following public attributes and methods at its core:\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "- `KEY_SEPARATOR`: A separator used to create unique keys for JSON objects, that allows for the inclusion of multiple entries of the same class within a JSON file.\n",
    "- `instance_mapping`: A dictionary linking class names to the actual class objects, enabling instantiation from stored configurations.\n",
    "\n",
    "**Methods:**\n",
    "- `save_instances_to_json`: Serializes a list of class instances into a JSON file.\n",
    "- `get_instances_from_json`: Reconstructs class instances with their specific parameters from a JSON file.\n",
    "- `get_randomized_instances_from_json`: Deserializes instances with parameters that are randomly chosen within defined ranges or distributions.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "The `ClassInstancesSerializer` is an important tool for converting complex class instances into JSON format and vice versa, which is essential for saving and loading the configurations of image preprocessing pipelines. The class is built on the premise that class instances must contain a `parameters` attribute, and optionally, an `arguments_datatype` for proper serialization and deserialization. This is because in addition to managing parameters, the `ClassInstancesSerializer` employs recursive type conversion to ensure that data types align correctly with class attributes. The attentive reader probably noticed that the data types of certain parameter values in the JSON file do not match the data types of the related preprocessing step parameter. That discrepancy is precisely why recursive type conversion is required as part of the serialization. To further clarify, this requirement derives from JSON's inherent inability to accurately represent some Python data structures, particularly tuples and nested tuples. More insights on the data type conversion of the image preprocessing framework can be found in [recursive_type_conversion_test.py](../../utils/tests/recursive_type_conversion_test.py). It is also important to highlight that the `instance_mapping` attribute is vital for initializing instances of mapped classes from configurations stored in JSON. \n",
    "\n",
    "For comprehensive implementation details, including how instances are serialized, deserialized, and instantiated with their parameters, the test framework, found in [class_instances_serializer_test.py](../../utils/tests/class_instance_serializer_test.py) of the image preprocessor is referenced. It provides examples and scenarios that demonstrate the serializer's capabilities in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='Chapter13'></a>\n",
    "## 12. Conclusion and Further Steps\n",
    "\n",
    "This documentation has described the structure of the image preprocessing framework developed for the task of PCB defect detection. It presented an organized framework for the application and experimentation of various preprocessing steps, whose contributions are expected to be effective in improving image data quality, which is crucial in ML image analysis. The framework has evolved into a tool that not only supports the storage and loading of preprocessing configurations, but also allows for parameter fine-tuning, which is made possible by the ability to randomize parameters.\n",
    "\n",
    "**Areas of Improvement**\n",
    "\n",
    "While the framework is expected to be a robust tool, opportunities for improvements are given. A feature for automating the selection and ordering of preprocessing steps could significantly increase efficiency in finding an appropriate pipeline (refere to [Appendix A](#appendix-a-preprocessing-step-sequence-randomization)). Furthermore, an optimized usage of TensorFlow's mapping function for the execution of preprocessing steps within `ImagePreprocessor` would speed up operations and potentially lead to performance gains.\n",
    "\n",
    "**Adapting for Wider Use**\n",
    "\n",
    "While the framework was initially designed to detect PCB defects, it may be applicable to other image-based ML tasks as well. Its design could potentially benefit different areas of image analysis with ML, but careful adaptation and testing would be required.\n",
    "\n",
    "**Next steps**\n",
    "\n",
    "Moving forward, the focus will shift to building the PCB Defect Detector Model. This step involves developing a model that makes the most of the developed image preprocessing framework for accurate defect detection on images. This means creating and training a model that uses the processed image data to detect defects precisely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Author's Q&A\n",
    "**Q: How does the ImagePreprocessor differ from and compare to the Scikit-learn Pipeline?**\n",
    "\n",
    "The `ImagePreprocessor` of the image preprocessing framework is inspired on scikit-learn's `Pipeline`, although its focus and functionality differ. It processes image data through a list of steps, defined in the attribute `pipeline` using a single `process` method, ensuring a consistent, non-adaptive flow. This approach differs from scikit-learn's `Pipeline`, which not only analyzes data but also learns from it using fit and transform methods, allowing for data-driven dynamic adaptability. As previously stated in the [chapter 4](#4-inspiration-and-framework-conceptualization). This difference highlights the `ImagePreprocessor`'s focus on executing a fixed sequence of image-specific preprocessing operations, whereas scikit-learn's `Pipeline` provides a more flexible, general and integrated approach capable of learning from and adapting to the data it processes.\n",
    "\n",
    "Furthermore, the `ImagePreprocessor` serves as the key orchestrator in its structure, handling a list of processing steps, collectively referred to as pipeline, that are specialized for image processing. Contrary to this, within the scikit-learn ecosystem, the `Pipeline` assumes the role of orchestrating the data processing workflow.\n",
    "\n",
    "**Q: What type of dataset is used in the PCB Defect Detection Project?**\n",
    "\n",
    "The dataset, called `image_dataset` from this yupiter notebook, is a TensorFlow dataset in the form of `tf.data.Dataset`. It consist of tuples, each containing an image as tensor of type `tf.uint8` and its associated defect category code of type `tf.int8`. This dataset is then prefetched to improve data loading efficiency during preprocessing and model training. The technique for constructing the `image_dataset` can be found in [get_tf_dataset.py](../../load_raw_data/get_tf_dataset.py).\n",
    "\n",
    "**Q: What influenced the decision to use TensorFlow's dataset format to represent image datasets in the preprocessing framework?**\n",
    "\n",
    "A: The primary motivation for using TensorFlow datasets (TDFS) in the form of `tf.data.Dataset` objects for image dataset representation is their inherent preformance characteristics and performance optimization features. These characteristics are very useful when dealing with great amounts of data. One cornerstone of TensorFlow's performance optimization, also used in the image preprocessing framework, is the parallelization of operations. This can be done by TensorFlow's data API's `map` function, intended to process data elements concurrently. This parallel processing considerably reduces the time required for data preparation and transformation.[[7]](#references). To demonstrate the efficiency, consider the execution time of the Python cells within this very Jupyter Notebook, which processed 693 images from the dataset using pipelines consisting of 5 to 6 preprocessing steps.\n",
    "\n",
    "However, while TensorFlow's dataset format provides significant performance benefits, it also presents debugging challenges due to its complex graph execution model. As a result, when implementing a preprocessing framework with TensorFlow, careful software development and thorough testing are required to ensure the the framework is working and to prevent difficulties.\n",
    "\n",
    "**Q: Why are images and targets kept together in the preprocessing pipeline?**\n",
    "\n",
    "A: Images and their matching targets are processed as pairs in the preprocessing pipeline to guarantee that each image remains correctly matched with its target. This strategy eliminates the possibility of an image being incorrectly linked with another target. Although this is a point of ongoing discussion, the strategy is being maintained for data integrity. In the development of the PCB defect detector model, the possibility of improving this aspect will be reconsidered to determine if separate image and target processing is more useful.\n",
    "\n",
    "**Q: What color channels are accepted in the image preprocessing framework?**\n",
    "\n",
    "A: The image preprocessing framework primarly focuses on grayscale and RGB color channels. This because: \n",
    "- Widespread use of RGB and grayscale: RGB and grayscale are the most widely used color channels in image processing, making them practical defaults for many applications.[[7][8]](#references).\n",
    "- Ease of visual inspection: Matplotlib, a popular Python package, provides handy methods for showing pictures in grayscale and RGB, making the visualization process easier during preprocessing.\n",
    "- Prevent unnecessary complication: Adding more color representations would complicate the framework inappropriately, which could impact performance and usability.\n",
    "\n",
    "Furthermore, the framework's preprocessing steps are intended to accept both grayscale and RGB inputs. They must output data in the same color space as the input, unless a specific step requires color channel conversion. This consistency in input and output color spaces guarantees that the preprocessing pipeline is uniform. However, if a preprocessing step necessitates a temporary conversion to a different color space for processing, it must convert the data back to its original color space before outputting. It is worth to mention, that this 'maintain the same color space' requirement is verified from a framework's test suite described in [single_step_test.py](../tests/single_step_test.py). The test suite ensures that a step complies with the aforementioned criteria before it is integrated into the pipeline. \n",
    "\n",
    "**Q: How are the input and output data types managed in the image preprocessing framework?**\n",
    "\n",
    "A: In the image preprocessing framework, the handling of data types for images and targets is carefully managed by each preprocessing step to ensure compatibility and efficiency:\n",
    "\n",
    "- Default Data Types:  The pipeline primarily uses tf.uint8 for images and tf.int8 for targets, as outlined in the [step_base.py](../preprocessing_steps/step_base.py) file. \n",
    "- Acceptance of Input Data Types: All preprocessing steps must accept images in the tf.uint8 default data type. This requirement is essential for mantaining constistency when executing multiple steps within a pipeline and is tested by the test suite in [single_step_test.py](../tests/single_step_test.py).\n",
    "- Variability in Accepted Data Types: The specific image data types that can be accepted as inputs may vary depending on the implementation of each preprocessing step. In the case that a step integrates an OpenCV function, for instance, the accepted input data types would depend from those that OpenCV supports.\n",
    "- Output Data Type of Images: The output data type for images from each preprocessing step can either adhere to the default (tf.uint8) or be a specific data type defined by the step itself. This is also tested in the previously stated test suite. This flexibility allows for steps that might require different data types due to the nature of their processing. However, any change from the default data type must be specified in detail in the step's docstring. \n",
    "\n",
    "Overall, the pipeline's design balances the need for standardization (via default data types) with the flexibility to accommodate specific preprocessing step requirements. This method guarantees that the pipeline is robust, modular, and capable of effectively handling a wide range of preprocessing tasks.\n",
    "\n",
    "**Q: What is the purpose of the _raise_step_process_exception attribute in the ImagePreprocessor class?**\n",
    "\n",
    "A: The `_raise_step_process_exception attribute` is a flag used to determine error handling behavior during the image preprocessing pipeline's execution. This variable, when set to False, guarantees that any exceptions that arise during a preprocessing step are properly logged rather than raised. In this case, the pipeline will halt the current processing, log the exception, return None, and proceed to the next preprocessing sequence, if available. This is especially helpful when processing several pipelines in as it's preferable to have uninterrupted execution even in the event that individual cases contain errors. On the other hand, standard exception handling occurs when this flag is set to True. Errors are raised instantaneously, stopping execution to enable prompt investigation and resolution.\n",
    "\n",
    "**Q: Why does StepBase only use the TensorFlow map method with the tf.py_function wrapper for its preprocessing steps?**\n",
    "\n",
    "A: The map method in TensorFlow is optimized for operations that are inherently TensorFlow functions. Nevertheless, almost all preprocessing step use Python-specific constructs, such as conditional statements to determine the number of color channels in an image tensor. These Pythonic expressions aren't natively supported in TensorFlow's computation graph without explicit wrapping. The `tf.py_function` wrapper offers this required wrapping, allowing these Pythonic components to be integrated into the TensorFlow workflow.\n",
    "\n",
    "In this context, an intricate bug was discovered where certain pipeline configurations led to unexpected behavior. For instance, applying a preprocessing step implemented with TensorFlow functions without the `tf.py_function` wrapper followed by a color channel conversion step resulted in the conversion not being executed for some specific pipeline configurations. This issue did not trigger any errors and was only uncovered through detailed debugging. It was discovered that using the `map` function directly with Pythonic functions, including basic constructs such as a single `if` statement, could result to unexpected behavior.\n",
    "\n",
    "Furthermore, there is room for optimization in this particular context as already mentioned in chapter [Conclusion and Futher steps](#12-conclusion-and-further-steps). Efficiency can be increased by refactoring steps that process tensors to use native TensorFlow functions (e.g., substituting TensorFlow's conditional operations for Python `if` statements). This would enable potential for a new decorator—possibly called `tensor_tffunc_wrapper`—that would improve processing efficiency by allowing direct mapping to TensorFlow functions without requiring `tf.py_function`.\n",
    "\n",
    "**Q:  Why do all arguments in the preprocessing step classes have default values?**\n",
    "\n",
    "A: There are three reasons for this:\n",
    "- Specify Format: They provide the format of each argument.\n",
    "- Starting Point for Experimantation: They provide a basic default value that can be used as a starting point for experimantation or as a reference for identifying appropriate values.\n",
    "- Improved Readability of Test Suite: Because default values can be used during instantiation, they improve the readability of the test suite for testing preprocessing procedures. Note: Omitting default values might lead to errors in some test cases that verify the functionality of the preprocessing step.\n",
    "\n",
    "**Q: Why was the JSON format chosen for serialization in the ClassInstancesSerializer?**\n",
    "\n",
    "A: Three significant considerations impacted the choice to use JSON in the `ClassInstancesSerializer`:\n",
    "\n",
    "- Editable: The static modifiability of JSON is a critical characteristic. It enables fast and direct changes to parameters, ranges, or distributions, which is not possible with formats such as pickle, which generates binary files.\n",
    "- Readability and Clarity: JSON stands out for its ease of use and widespread acceptance, allowing for transparent serialized data management. In comparison, XML, while still human readable, is more verbose and less user-friendly.\n",
    "- Hierarchical Data Representation: Because the configuration of the preprocessing pipeline is inherently complicated, it benefits from a format that can effectively describe hierarchical structures. JSON outperforms CSV in this aspect, whereas CSV is better suited for simpler, tabular data and can become tedious with complex nested data.\n",
    "\n",
    "In conclusion, JSON was chosen because of its simplicity of modification, readability, and flexibility to express complicated hierarchical data structures. These characteristics make it a solid option for serialized data management within the image preprocessing framework.\n",
    "\n",
    "**Q: In the JSON configuration of the preprocessing pipeline, is there a method to include the same preprocessing step multiple times without causing conflicts?**\n",
    "\n",
    " While it is relatively rare to encounter such a scenario, it is indeed possible to include the same preprocessing step multiple times within a JSON-configured preprocessing pipeline. In this case, to avoid potential conflicts with the JSON format, a unique key naming mechanism is employed. This is where the method `_generate_unique_key_name method` of the `ClassInstancesSerializer` becomes crucial. The class and the method are defined in [class_instances_serializer.py](../../utils/class_instances_serializer.py).\n",
    "\n",
    "The following approach can be used:\n",
    "\n",
    "1. Base Step Naming: Start with the base name of the preprocessing step (e.g., 'Standard Normalizer').\n",
    "1. Applying `KEY_SEPARATOR`: Use the `KEY_SEPARATOR` from `ClassInstancesSerializer` to append a unique identifier. The `KEY_SEPARATOR` is typically '__'.\n",
    "1. Unique Identifier: Assign a distinct identifier for each instance (e.g., '2', '3', etc.).\n",
    "\n",
    "Example Configuration:\n",
    "\n",
    "First instance: 'Standard Normalizer'  \n",
    "Second instance: 'Standard Normalizer__2'  \n",
    "Third instance: 'Standard Normalizer__3'  \n",
    "\n",
    "This approach allows each preprocessing step to be uniquely identified, allowing multiple occurrences of the same step to be included in the pipeline without conflict. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='references'></a>\n",
    "## References\n",
    "\n",
    "[1] G. Mahalingam, K. M. Gay, K. Ricanek, \"PCB-METAL: A PCB Image Dataset for Advanced Computer Vision Machine Learning Component Analysis\", _IEEE Xplore_, 2019. [Online]. Available: https://ieeexplore.ieee.org/document/8757928. Accessed December 4, 2023.\n",
    "\n",
    "[2] J. Nelson, \"What is Image Preprocessing and Augmentation?\" _Roboflow Blog_, Jan 26, 2020. [Online]. Available: https://blog.roboflow.com/why-preprocess-augment/. Accessed December 4, 2023.\n",
    "\n",
    "[3] Isahit, \"What is the purpose of image preprocessing in deep learning?\", Oct 11, 2022. _Isahit_. [Online]. Available: https://www.isahit.com/blog/what-is-the-purpose-of-image-preprocessing-in-deep-learning. Accessed December 4, 2023.\n",
    "\n",
    "[4] S. Krig, \"Image Pre-Processing,\" in _Computer Vision Metrics_, Springer, pp. 39–83, First Online: May 26, 2014. [Online]. Available: https://link.springer.com/chapter/10.1007/978-1-4302-5930-5_2. Accessed December 4, 2023.\n",
    "\n",
    "[5] N. Elter, \"PCB Defect dataset,\" Kaggle, updated Aug 2023. Available: https://www.kaggle.com/datasets/norbertelter/pcb-defect-dataset. Accessed December 4, 2023.\n",
    "\n",
    "[6] Scikit-learn developers, \"Pipeline: scikit-learn,\" Scikit-learn stable documentation, 2023. [Online]. Available: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html. Accessed December 4, 2023.\n",
    "\n",
    "[7] TensorFlow developers, \"Better performance with the tf.data API,\" TensorFlow Core v2.14.0 documentation, 2023. [Online]. Available: https://www.tensorflow.org/guide/data_performance. Accessed December 4, 2023.\n",
    "\n",
    "[8] Scaler Topics, \"Color Spaces in Image Processing,\" Scaler Topics, 2023. [Online]. Available: https://www.scaler.com/topics/color-spaces-in-image-processing/. Accessed December 4, 2023.\n",
    "\n",
    "[9] Dynamsoft Blog, \"Image Processing 101 Chapter 1.3: Color Space Conversion,\" Dynamsoft Blog, May 24, 2019. [Online]. Available: https://www.dynamsoft.com/blog/insights/image-processing-101-color-space-conversion/. Accessed December 4, 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='appendix'></a>\n",
    "## Appendix A: Preprocessing Step Sequence Randomization\n",
    "This appendix provides a detailed explanation of the preprocessing step sequence randomization feature. This feature allows for the randomization of the sequence of preprocessing steps in the pipeline. Imagine that a pipeline with three steps is needed and the precise preprocessing steps are desired to be specified by probability. Take the image above, for instance.\n",
    "\n",
    "![Probabilistic Preprocessing Pipeline Configuration](related/pipeline_sequence_randomisation_image.png)<br>\n",
    "\n",
    "The aforementioned feature in the image preprocessing framework allows the user to specify the probability that a preprocessing step will be included at a specific pipeline index.  A JSON file can be used to build a pipeline that reflects the probabilities shown in the image above, as demonstrated below:\n",
    "\n",
    "    {\n",
    "        \"Adaptive Histogram Equalizer__I0F75\": {\n",
    "            \"clip_limit\": [1.0, 2.0, 2.0, 3.0, 4.0],\n",
    "            \"tile_gridsize\": [[4,4], [6,6], [8,8], [10,10]]\n",
    "        },\n",
    "        \"Global Histogram Equalizer__I0F25\": {},\n",
    "        \"Gaussian Blur Filter__I1F33\": {\n",
    "            \"kernel_size\": [[5, 5],[8,8]],\n",
    "            \"sigma\": [0.3, 0.5, 0.7, 0.9]\n",
    "        },\n",
    "        \"Median Blur Filter__I1F33\": {\n",
    "            \"kernel_size\": [5, 7, 9]\n",
    "        },\n",
    "        \"Bilateral Filter__I1F34\": {\n",
    "            \"diameter\": [9, 11, 13],\n",
    "            \"sigma_color\": [75, 100, 125],\n",
    "            \"sigma_space\": [75, 100, 125]\n",
    "        },\n",
    "        \"Standard Normalizer__I2F50\": {},\n",
    "        \"Mean Normalizer__I2F50\": {}\n",
    "    }\n",
    "\n",
    "To configure the `ImagePreprocessor` with the discussed pipeline, copy the above entry into [pipeline.json](./related/pipeline.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell several times to observe how the step sequence vary.\n",
    "preprocessor.load_randomized_pipe_from_json(json_path)\n",
    "print(preprocessor.get_pipe_code_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Understanding the Key Naming Convention\n",
    "Attentive readers may recognize the naming pattern *__I{index}F{frequency}* within the keys. This pattern is crucial for the randomization of the preprocessing step sequence. The *index* specifies the position of the preprocessing step in the pipeline, while the *frequency* specifies the probability that the step will be included in the pipeline. The *index* is prefixed by the character *I* and the frequency is prefixed by the character *F*. The following examples illustrate the usage of the pattern:\n",
    "\n",
    "- *\"Adaptive Histogram Equalizer__I0F75\"*: Places the `AdaptiveHistogramEqualizer` at index 0 with a 75% inclusion probability.\n",
    "- *\"Global Histogram Equalizer__I0F25\"*: Assigns the `GlobalHistogramEqualizer` to index 0 with a 25% inclusion probability.\n",
    "- ...and so forth for each entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In summary\n",
    "The feature allowing for the `ImagePreprocessor`'s preprocessing step sequence randomization was explained in the previous text. Through the usage of this function, users can configure their image preprocessing pipelines with a probabilistic flexibility, thereby efficiently customizing the preprocessing stages to precisely tune hyperparameters.\n",
    "\n",
    "This functionality is based on the [sequential_keys_randomly_select.py](../../utils/randomly_select_sequential_keys.py) script. For a detailed explanation and verification of the feature's functionality, see [randomly_select_sequential_keys_test.py](../../utils/tests/randomly_sequential_keys_test.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
